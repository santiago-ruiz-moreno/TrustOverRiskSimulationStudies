---
title: "Simulations of Trust Game"
author: "J. Santiago Ruiz M"
date: "`r Sys.Date()`"
output:
  pdf_document:
    keep_tex: true
    fig_caption: yes
    latex_engine: xelatex
  html_document:
    keep_md: true
    fig_caption: yes
header-includes:
  - \usepackage{booktabs}
---

# Simulations of Trust over Risk Game with LLM Interventions

This document presents a simulation study of a repeated trust game, designed to
evaluate the effects of different treatments—LLMdelegation, LLMadvice, and
control—on principal trust, agent risk-taking, and punishment behavior. The
simulation models a scenario where, in each round, a principal decides whether
to trust an agent, and the agent then chooses between a safe action ("keep") and
a risky action ("Gamble A"). The probabilities of these actions, as well as the
expected punishment, are parameterized by treatment. This document concerns only
the main hypotheses without the mediators, check the rmd file to see the code
and the simulation setup.

The simulation is based on several key assumptions regarding the distributions
of actions and the expected effect sizes as described in Table 1.
For instance, we anticipate for the agent's choice, the
probability of selecting the riskier "Gamble A" to be 1.0 for LLMdelegation,
0.8 for LLMadvice, and 0.5 for the baseline.

- **Principal Trust**: The probability that a principal chooses to trust the agent is modeled as a function of the agent's treatment. Formally, the hypothesis is tested using a logistic mixed effects model:
  
  $$
  Trust_{ij} = \beta_0 + \beta_1 \cdot \text{LLMdelegation}_{ij} + \beta_2 \cdot \text{LLMadvice}_{ij} + u_j
  $$
  where $u_j$ is a random intercept for each principal.

- **Agent Riskier Action**: The likelihood that the agent chooses the riskier action ("Gamble A") is also modeled as a function of treatment, using a logistic mixed effects model:
  
  $$
  \text{logit}(\Pr(\text{GambleA}_{ij} = 1)) = \gamma_0 + \gamma_1 \cdot \text{LLMdelegation}_{ij} + \gamma_2 \cdot \text{LLMadvice}_{ij} + v_j
  $$
  where $v_j$ is a random intercept for each agent.

- **Punishment**: The amount of punishment assigned by the principal is modeled with a linear mixed effects model:
  
  $$
  \text{Punishment}_{ij} = \alpha_0 + \alpha_1 \cdot \text{LLMdelegation}_{ij} + \alpha_2 \cdot \text{LLMadvice}_{ij} + w_j + \epsilon_{ij}
  $$
  where $w_j$ is a random intercept for each agent and $\epsilon_{ij}$ is the residual error.

The simulation iterates over multiple sample sizes and repetitions to estimate the statistical power for detecting treatment effects in each model.
 The results are summarized in regression tables and power curves, providing guidance for experimental design and sample size planning.

Participants are rematched in groups of 2, with each group playing 3 rounds of the trust over risk game. We made the following assumptions
about the estimated effect sizes of the experimnt:

Below are the key simulation parameters for each treatment group. The table summarizes the assumed probabilities and means ($p$, $\mu$), as well as standard deviations ($\sigma$) for trust, agent actions, and punishment.

\begin{table}[ht]
\centering
\begin{tabular}{lccc}
\toprule
 & \textbf{LLMdelegation} & \textbf{LLMadvice} & \textbf{Control} \\
\midrule
Principal trust probability ($p_\text{trust}$) & 0.8 & 0.6 & 0.5 \\
Mean trust sent ($\mu_\text{trust}$) & 6 & 6 & 5 \\
SD trust sent ($\sigma_\text{trust}$) & 3.2 & 3.2 & 3.2 \\
Agent "keep" probability ($p_\text{keep}$) & 0.05 & 0.05 & 0.05 \\
Agent "Gamble A" probability ($p_\text{GambleA}$) & 1.0 & 0.8 & 0.5 \\
Mean punishment ($\mu_\text{punish}$) & 0 & 0 & 2 \\
SD punishment ($\sigma_\text{punish}$) & 2 & 2 & 2 \\
\bottomrule
\end{tabular}
\caption{Simulation parameters for each treatment group: probabilities ($p$), means ($\mu$), and standard deviations ($\sigma$).}
\end{table}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(reshape2)
library(dplyr)

set.seed(123) # for reproducibility
repetitions <- 1000 # Number of repetitions for the simulation
number_of_groups = 150
rounds = 3
players_per_group = 2
total_players = number_of_groups*2
treatments <- c("LLMdelegation", "LLMadvice", "control")

# Define probabilities and payoffs for the gambles
gamble_probs <- list(
    "Gamble A" = c(0.95, 0.05),
    "Gamble B" = c(0.95, 0.05)
)
gamble_payoffs <- list(
    "Gamble A" = c(26, -1),
    "Gamble B" = c(21, 23)
)



# Expected results based on standard deviations from Berg 1995. sd = 3.2
# Previous simulations suggest that sample sizes smalles than 250 < don't have
# enough power to detect differences in mean trust between groups
# smaller than 2.5 (Cohen's d = 0.7)
# Define trust probabilities for each treatment (probability principal gives >1 token)
trust_probs <- c(
    "LLMdelegation" = 0.8,
    "LLMadvice" = 0.6,
    "control" = 0.5
)

trust_means <- c(
    "LLMdelegation" = 6,
    "LLMadvice" = 6,
    "control" = 5
)

trust_sds <- c(
    "LLMdelegation" = 3.2,
    "LLMadvice" = 3.2,
    "control" = 3.2
)

# Probability agent chooses "keep" is always 5%
prob_keep <- 0.05

# Probability agent chooses "Gamble A" (from gambleA_probs), "Gamble B" gets the remainder
gambleA_probs <- c(
    "LLMdelegation" = 1,
    "LLMadvice" = 0.8,
    "control" = 0.5
)

punishment_means <- c(
    "LLMdelegation" = 0,
    "LLMadvice" = 0,
    "control" = 2
)

punishment_sds <- c(
    "LLMdelegation" = 2,
    "LLMadvice" = 2,
    "control" = 2
)

# Function to simulate the trust game with parameterized action probabilities and punishment
# All key behavioral probabilities and punishment parameters are passed as arguments per treatment

simulate_trust_game <- function(
    n, 
    rounds, 
    treatments,
    gambleA_probs,       # named vector: probability agent chooses Gamble A, per treatment
    punishment_means,    # named vector: mean of punishment, per treatment
    punishment_sds,      # named vector: sd of punishment, per treatment
    trust_means = NULL,  # named vector: mean of continuous trust, per treatment
    trust_sds = NULL     # named vector: sd of continuous trust, per treatment
) {
    agents <- data.frame(
        id = 1:n,
        treatment = sample(rep(treatments, length.out = n))
    )
    principals <- data.frame(
        id = 1:n
    )

    results <- data.frame(
        group_id = character(),
        principal_id = integer(),
        agent_id = integer(),
        round = integer(),
        principal_tokens = numeric(),
        agent_action = character(),
        agent_treatment = character(),
        principal_payoff = numeric(),
        agent_payoff = numeric(),
        punishment = numeric(),
        trust_continuous = numeric()
    )

    for (round in 1:rounds) {
        available_agents <- agents
        principal_ids <- sample(principals$id, n)
        agent_ids <- rep(NA, n)
        agent_treatments <- rep(NA, n)

        for (i in seq_along(principal_ids)) {
            pid <- principal_ids[i]
            chosen_idx <- sample(seq_len(nrow(available_agents)), 1)
            chosen_agent <- available_agents[chosen_idx, ]
            agent_ids[i] <- chosen_agent$id
            agent_treatments[i] <- chosen_agent$treatment
            available_agents <- available_agents[available_agents$id != chosen_agent$id, ]
        }

        for (i in 1:n) {
            principal_id <- principal_ids[i]
            agent_id <- agent_ids[i]
            treatment <- agent_treatments[i]
            group_id <- paste0(principal_id, "-", agent_id)

            # Principal chooses how many tokens to send (0-10), but only >1 is "trust"
            p_trust <- trust_probs[[treatment]]
            send_tokens <- ifelse(rbinom(1, 1, p_trust) == 1, sample(2:10, 1), sample(0:1, 1))

            # Continuous trust variable: normal distribution, treatment-specific mean/sd, truncated to [0,10]
            trust_cont <- NA
            if (!is.null(trust_means) && !is.null(trust_sds)) {
                trust_cont <- rnorm(1, mean = trust_means[[treatment]], sd = trust_sds[[treatment]])
                trust_cont <- min(max(trust_cont, 0), 10)
            }

            principal_payoff <- NA
            agent_payoff <- NA
            punishment <- 0

            if (send_tokens <= 1) {
                agent_action <- NA
                principal_payoff <- 10 - send_tokens
                agent_payoff <- send_tokens
                punishment <- 0
            } else {
                # Agent chooses action: "keep" (5%), "Gamble A" (X%), "Gamble B" (remainder)
                p_keep <- prob_keep
                p_gambleA <- gambleA_probs[[treatment]] * (1 - p_keep)
                p_gambleB <- (1 - p_keep) - p_gambleA
                action_choices <- c("keep", "Gamble A", "Gamble B")
                action_probs <- c(p_keep, p_gambleA, p_gambleB)
                agent_action <- sample(action_choices, 1, prob = action_probs)

                if (agent_action == "keep") {
                    agent_payoff <- send_tokens * 3
                    principal_payoff <- 10 - send_tokens
                } else if (agent_action == "Gamble A") {
                    probs <- gamble_probs[["Gamble A"]]
                    payoffs <- gamble_payoffs[["Gamble A"]]
                    outcome <- sample(1:2, 1, prob = probs)
                    agent_payoff <- payoffs[outcome]
                    principal_payoff <- 30 - agent_payoff
                } else if (agent_action == "Gamble B") {
                    probs <- gamble_probs[["Gamble B"]]
                    payoffs <- gamble_payoffs[["Gamble B"]]
                    outcome <- sample(1:2, 1, prob = probs)
                    agent_payoff <- payoffs[outcome]
                    principal_payoff <- 30 - agent_payoff
                }

                # Punishment: normal distribution, treatment-specific mean/sd
                punishment <- rnorm(1, mean = punishment_means[[treatment]], sd = punishment_sds[[treatment]])
            }

            results <- rbind(results, data.frame(
                group_id = group_id,
                principal_id = principal_id,
                agent_id = agent_id,
                round = round,
                principal_tokens = send_tokens,
                agent_action = agent_action,
                agent_treatment = treatment,
                principal_payoff = principal_payoff,
                agent_payoff = agent_payoff,
                punishment = punishment,
                trust_continuous = trust_cont
            ))
        }
    }
    return(results)
}

results <- simulate_trust_game(
    n = number_of_groups,
    rounds = rounds,
    treatments = treatments,
    gambleA_probs = gambleA_probs,
    punishment_means = punishment_means,
    punishment_sds = punishment_sds,
    trust_means = trust_means,
    trust_sds = trust_sds
)


```



```{r regression, echo=FALSE, results='asis'}
library(lme4)
library(broom.mixed)
library(knitr)
library(stargazer)

# Runing regressions for main hypotheses

# Hypothesis 1: Principals trust more participants who are either in the LLMadvice or in the LLMdelegation treatment
# Mixed effects regression model with participant as random effect

run_regressions <- function(results, treatments) {
    # Convert to binary outcome
    results$agent_treatment <- factor(
        results$agent_treatment, levels = treatments
    )
    # Model 1: Set 'control' as the baseline for agent_treatment
    results$agent_treatment <- relevel(results$agent_treatment, ref = "control")
    # Round trust_continuous to 2 digits
    results$trust_continuous <- round(results$trust_continuous, 2)
    model1 <- glmer(
        trust_continuous ~ agent_treatment + (1 | principal_id),
        data = results,
        family = gaussian()
    )

    # Model 2: Agent riskier action
    results$riskier_action <- ifelse(results$agent_action == "Gamble A", 1, 0)
    model2 <- glmer(
        riskier_action ~ agent_treatment + (1 | agent_id),
        data = results,
        family = binomial
    )

    # Model 3: Punishment (using lmer for linear mixed effects)
    model3 <- lmer(
        punishment ~ agent_treatment + (1 | agent_id),
        data = results
    )

    list(model1 = model1, model2 = model2, model3 = model3)
}

regression_models <- run_regressions(results, treatments)
model1 <- regression_models$model1
model2 <- regression_models$model2
model3 <- regression_models$model3

# Output all models in one professional table using stargazer
stargazer(
  model1, model2, model3,
  type = "latex",
  title = "Mixed Effects Regression Results",
  dep.var.labels = c("Principal Trust (logit)", "Riskier Action by Agent (logit)", "Punishment (linear)"),
  covariate.labels = c("LLMdelegation", "LLMadvice"),
  column.labels = c("Principal Trust", "Riskier Action", "Punishment"),
  model.numbers = FALSE,
  single.row = FALSE,
  report = "vc*", # show coefficients and standard errors
  digits = 3,
  star.cutoffs = c(0.05, 0.01, 0.001),
  notes = "Standard errors in parentheses. * p<0.05, ** p<0.01, *** p<0.001", header = FALSE
)

```

# Simulation Results

```{r results_summary, echo=FALSE, results='asis'}
library(itertools)
library(pbapply)

# Helper to extract p-values from glmer model
extract_pvals <- function(model) {
    coefs <- summary(model)$coefficients
    # For agent_treatmentLLMdelegation and agent_treatmentLLMadvice
    if ("Pr(>|z|)" %in% colnames(coefs)) {
        # For binomial models (glmer)
        pvals <- coefs[grepl("agent_treatment", rownames(coefs)), "Pr(>|z|)", drop=FALSE]
    } else if ("t value" %in% colnames(coefs)) {
        # For gaussian models (lmer/glmer with gaussian)
        tvals <- coefs[grepl("agent_treatment", rownames(coefs)), "t value", drop=FALSE]
        # Approximate p-values using normal distribution
        pvals <- 2 * (1 - pnorm(abs(tvals)))
    } else {
        stop("No p-value or t value column found in model coefficients.")
    }
    return(as.numeric(pvals))
}
# Main simulation loop (store only p-values, no power calculation)
set.seed(123)
sample_sizes <- seq(90, 240, by = 30)
repts_per_sample_size <- 200

# Progress bar
total_iters <- length(sample_sizes) * repts_per_sample_size
pb <- txtProgressBar(min = 0, max = total_iters, style = 3)
iter_count <- 0
# Check if cache exists
if (file.exists("simulation_pval_cach_trust_continuous.rds")) {
    cat("Simulation cache already exists. Skipping simulation and using cached results.\n")
} else {
    # Store results
    pval_cache <- list()

    for (n_groups in sample_sizes) {
        pvals_model1 <- matrix(NA, nrow = repts_per_sample_size, ncol = 2) # delegation, advice
        pvals_model2 <- matrix(NA, nrow = repts_per_sample_size, ncol = 2)
        pvals_model3 <- matrix(NA, nrow = repts_per_sample_size, ncol = 2)
        
        for (rep in 1:repts_per_sample_size) {
            sim_data <- simulate_trust_game(
                n = n_groups,
                rounds = rounds,
                treatments = treatments,
                gambleA_probs = gambleA_probs,
                punishment_means = punishment_means,
                punishment_sds = punishment_sds,
                trust_means = trust_means,
                trust_sds = trust_sds
            )
            models <- run_regressions(sim_data, treatments)
            # Model 1: trust
            pvals_model1[rep, ] <- extract_pvals(models$model1)
            # Model 2: riskier action
            pvals_model2[rep, ] <- extract_pvals(models$model2)
            # Model 3: punishment
            pvals_model3[rep, ] <- extract_pvals(models$model3)
            iter_count <- iter_count + 1
            setTxtProgressBar(pb, iter_count)
        }
        pval_cache[[as.character(n_groups)]] <- list(
            model1 = pvals_model1,
            model2 = pvals_model2,
            model3 = pvals_model3
        )
    }
    close(pb)

    # Save cache for later use
    saveRDS(pval_cache, file = "simulation_pval_cach_trust_continuous.rds")
}


```

```{r plot_power, echo=FALSE, fig.cap="Estimated Power by Sample Size and Model"}


pval_cache <- readRDS("simulation_pval_cach_trust_continuous.rds")

# Prepare data for plotting
power_df <- data.frame()
for (n_groups in names(pval_cache)) {
    for (model in c("model1", "model2", "model3")) {
        pvals <- pval_cache[[n_groups]][[model]]
        if (!is.null(pvals)) {
            power_vals <- colMeans(pvals < 0.05, na.rm = TRUE)
            power_df <- rbind(
                power_df,
                data.frame(
                    SampleSize = as.numeric(n_groups),
                    Model = switch(model,
                                   model1 = "Principal Trust",
                                   model2 = "Riskier Action",
                                   model3 = "Punishment"),
                    Treatment = "LLMdelegation",
                    Power = power_vals[1]
                ),
                data.frame(
                    SampleSize = as.numeric(n_groups),
                    Model = switch(model,
                                   model1 = "Principal Trust",
                                   model2 = "Riskier Action",
                                   model3 = "Punishment"),
                    Treatment = "LLMadvice",
                    Power = power_vals[2]
                )
            )
        }
    }
}


# Prepare summary table: average power by sample size, model, and treatment
power_table <- dcast(
    power_df,
    SampleSize + Model ~ Treatment,
    value.var = "Power"
)
# Add Greek letters and subscripts to clarify which parameter each power value refers to
# LLMdelegation: β₁ (Principal Trust), γ₁ (Riskier Action), α₁ (Punishment)
# LLMadvice: β₂ (Principal Trust), γ₂ (Riskier Action), α₂ (Punishment)

# Create new column names with Greek letters and subscripts

colnames(power_table) <- c(
    "Sample Size",
    "Model",
    "$\\beta_1$, $\\gamma_1$, $\\alpha_1$ (LLMdelegation)",
    "$\\beta_2$, $\\gamma_2$, $\\alpha_2$ (LLMadvice)"
)

# Collapse repeated Sample Size values for display
power_table_display <- power_table
power_table_display$`Sample Size` <- ifelse(
    duplicated(power_table_display$`Sample Size`), "", power_table_display$`Sample Size`
)

knitr::kable(
    power_table_display,
    format = "latex",
    caption = "Estimated Power for Hypothesis Tests of Treatment Effects: $\\beta_1$, $\\beta_2$ (Principal Trust); $\\gamma_1$, $\\gamma_2$ (Riskier Action); $\\alpha_1$, $\\alpha_2$ (Punishment)",
    digits = 2,
    booktabs = TRUE,
    row.names = FALSE,
    escape = FALSE
) %>%
  kableExtra::kable_styling(
    latex_options = c("hold_position"),
    position = "center",
    latex_table_env = "tabular",
    font_size = 10,
    full_width = FALSE
  ) %>%
  kableExtra::row_spec(0:nrow(power_table_display), extra_latex_after = "[1.5ex]")

```